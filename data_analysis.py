# -*- coding: utf-8 -*-
"""data_analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15UL-dQOmMBtBR5yGj3byguwvEt7sOrgm
"""

import dask.dataframe as dd
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import HashingVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from scipy.stats import pearsonr
from typing import List, Tuple
import multiprocessing as mp
from functools import partial

def determine_column_types(chunk: pd.DataFrame) -> dict:
    column_types = {}
    for column in chunk.columns:
        if pd.api.types.is_string_dtype(chunk[column]):
            column_types[column] = 'string'
        elif pd.api.types.is_numeric_dtype(chunk[column]):
            column_types[column] = 'numeric'
        else:
            column_types[column] = 'unknown'
    return column_types

def compare_columns(col1: pd.Series, col2: pd.Series) -> float:
    if pd.api.types.is_string_dtype(col1) and pd.api.types.is_string_dtype(col2):
        vectorizer = HashingVectorizer(n_features=1000)
        vec1 = vectorizer.fit_transform(col1.astype(str).fillna(''))
        vec2 = vectorizer.transform(col2.astype(str).fillna(''))
        # Convert to numpy arrays before cosine similarity
        vec1 = np.asarray(vec1.mean(axis=0))
        vec2 = np.asarray(vec2.mean(axis=0))
        return cosine_similarity(vec1, vec2)[0][0]
    elif pd.api.types.is_numeric_dtype(col1) and pd.api.types.is_numeric_dtype(col2):
        return abs(pearsonr(col1.fillna(0), col2.fillna(0))[0])
    else:
        return 0.0

def process_chunk(chunk1: pd.DataFrame, df2: pd.DataFrame) -> List[Tuple[str, str, float]]:
    similar_columns = []
    for col1 in chunk1.columns:
        for col2 in df2.columns:
            similarity = compare_columns(chunk1[col1], df2[col2])
            if similarity > 0.8:
                similar_columns.append((col1, col2, similarity))
    return similar_columns

def main():
    file1 = 'sample1.csv'
    file2 = 'sample2.csv'

    print("Loading second file...")
    df2 = dd.read_csv(file2).compute()

    print("Loading first file in chunks...")
    df1 = dd.read_csv(file1, blocksize="10MB")

    print("Determining column types...")
    types1 = determine_column_types(df1.head(1))
    types2 = determine_column_types(df2)

    print("Column types for Sample 1:")
    for col, type in types1.items():
        print(f"{col}: {type}")

    print("Column types for Sample 2:")
    for col, type in types2.items():
        print(f"{col}: {type}")

    print("Comparing columns...")

    pool = mp.Pool(mp.cpu_count())
    similar_columns = []

    for delayed_chunk in df1.to_delayed():
        chunk = delayed_chunk.compute()
        chunk_results = pool.apply_async(process_chunk, args=(chunk, df2))
        similar_columns.extend(chunk_results.get())

    pool.close()
    pool.join()

    similar_columns = sorted(set(similar_columns), key=lambda x: x[2], reverse=True)

    print("Similar columns:")
    for col1, col2, similarity in similar_columns:
        print(f"{col1} (Sample 1) and {col2} (Sample 2) - Similarity: {similarity:.2f}")

if __name__ == "__main__":
    main()

