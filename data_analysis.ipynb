{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmjLLkYKrPO3",
        "outputId": "b8e03d27-dd13-4e78-fd64-29dff8e36c88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading second file...\n",
            "Loading first file in chunks...\n",
            "Determining column types...\n",
            "Column types for Sample 1:\n",
            "First Name: string\n",
            "Last Name: string\n",
            "Mobile Number: numeric\n",
            "Date: string\n",
            "Email: string\n",
            "Address: string\n",
            "Column types for Sample 2:\n",
            "Email: string\n",
            "Account Balance: string\n",
            "User ID: string\n",
            "Meter No: string\n",
            "Meter Reading: numeric\n",
            "Comparing columns...\n",
            "Similar columns:\n",
            "Email (Sample 1) and Email (Sample 2) - Similarity: 1.00\n"
          ]
        }
      ],
      "source": [
        "import dask.dataframe as dd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.stats import pearsonr\n",
        "from typing import List, Tuple\n",
        "import multiprocessing as mp\n",
        "from functools import partial\n",
        "\n",
        "def determine_column_types(chunk: pd.DataFrame) -> dict:\n",
        "    column_types = {}\n",
        "    for column in chunk.columns:\n",
        "        if pd.api.types.is_string_dtype(chunk[column]):\n",
        "            column_types[column] = 'string'\n",
        "        elif pd.api.types.is_numeric_dtype(chunk[column]):\n",
        "            column_types[column] = 'numeric'\n",
        "        else:\n",
        "            column_types[column] = 'unknown'\n",
        "    return column_types\n",
        "\n",
        "def compare_columns(col1: pd.Series, col2: pd.Series) -> float:\n",
        "    if pd.api.types.is_string_dtype(col1) and pd.api.types.is_string_dtype(col2):\n",
        "        vectorizer = HashingVectorizer(n_features=1000)\n",
        "        vec1 = vectorizer.fit_transform(col1.astype(str).fillna(''))\n",
        "        vec2 = vectorizer.transform(col2.astype(str).fillna(''))\n",
        "        vec1 = np.asarray(vec1.mean(axis=0))\n",
        "        vec2 = np.asarray(vec2.mean(axis=0))\n",
        "        return cosine_similarity(vec1, vec2)[0][0]\n",
        "    elif pd.api.types.is_numeric_dtype(col1) and pd.api.types.is_numeric_dtype(col2):\n",
        "        return abs(pearsonr(col1.fillna(0), col2.fillna(0))[0])\n",
        "    else:\n",
        "        return 0.0\n",
        "\n",
        "def process_chunk(chunk1: pd.DataFrame, df2: pd.DataFrame) -> List[Tuple[str, str, float]]:\n",
        "    similar_columns = []\n",
        "    for col1 in chunk1.columns:\n",
        "        for col2 in df2.columns:\n",
        "            similarity = compare_columns(chunk1[col1], df2[col2])\n",
        "            if similarity > 0.8:\n",
        "                similar_columns.append((col1, col2, similarity))\n",
        "    return similar_columns\n",
        "\n",
        "def main():\n",
        "    file1 = 'SampleData1.csv'\n",
        "    file2 = 'SampleData2.csv'\n",
        "\n",
        "    print(\"Loading second file...\")\n",
        "    df2 = dd.read_csv(file2).compute()\n",
        "\n",
        "    print(\"Loading first file in chunks...\")\n",
        "    df1 = dd.read_csv(file1, blocksize=\"10MB\")\n",
        "\n",
        "    print(\"Determining column types...\")\n",
        "    types1 = determine_column_types(df1.head(1))\n",
        "    types2 = determine_column_types(df2)\n",
        "\n",
        "    print(\"Column types for Sample 1:\")\n",
        "    for col, type in types1.items():\n",
        "        print(f\"{col}: {type}\")\n",
        "\n",
        "    print(\"Column types for Sample 2:\")\n",
        "    for col, type in types2.items():\n",
        "        print(f\"{col}: {type}\")\n",
        "\n",
        "    print(\"Comparing columns...\")\n",
        "\n",
        "    pool = mp.Pool(mp.cpu_count())\n",
        "    similar_columns = []\n",
        "\n",
        "    for delayed_chunk in df1.to_delayed():\n",
        "        chunk = delayed_chunk.compute()\n",
        "        chunk_results = pool.apply_async(process_chunk, args=(chunk, df2))\n",
        "        similar_columns.extend(chunk_results.get())\n",
        "\n",
        "    pool.close()\n",
        "    pool.join()\n",
        "\n",
        "    similar_columns = sorted(set(similar_columns), key=lambda x: x[2], reverse=True)\n",
        "\n",
        "    print(\"Similar columns:\")\n",
        "    for col1, col2, similarity in similar_columns:\n",
        "        print(f\"{col1} (Sample 1) and {col2} (Sample 2) - Similarity: {similarity:.2f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def process_csv(csv_file):\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    rows, columns = df.shape\n",
        "    print(f'Number of Rows: {rows}')\n",
        "    print(f'Number of Columns: {columns}')\n",
        "\n",
        "    required_columns = ['First Name', 'Last Name','Mobile Number']\n",
        "    if not all(col in df.columns for col in required_columns):\n",
        "        print(\"Error: CSV file does not contain the required columns.\")\n",
        "        return\n",
        "\n",
        "    print(\"\\nNames and Phone Numbers:\")\n",
        "    for _, row in df[required_columns].iterrows():\n",
        "        print(f\"Name: {row['First Name']} {row['Last Name']}, Phone Number: {row['Mobile Number']}\")\n",
        "\n",
        "\n",
        "csv_file = 'SampleData1.csv'\n",
        "process_csv(csv_file)"
      ],
      "metadata": {
        "id": "cx3hr35qriYY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4015e1da-4ff7-4420-84dd-b63012756898"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Rows: 6\n",
            "Number of Columns: 6\n",
            "\n",
            "Names and Phone Numbers:\n",
            "Name: John Saint, Phone Number: 1234567890\n",
            "Name: Abraham Lincoln, Phone Number: 9876543021\n",
            "Name: Rahim Mohammed, Phone Number: 8765123490\n",
            "Name: Harry Potter, Phone Number: 4321567089\n",
            "Name: Bruce Wayne, Phone Number: 6789043215\n",
            "Name: Kara ZorEl, Phone Number: 1234509876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dtsHkpUrumvS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}