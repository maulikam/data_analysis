{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmjLLkYKrPO3",
        "outputId": "a210201d-4fa7-495e-9f29-c131c9f4a8e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading second file...\n",
            "Loading first file in chunks...\n",
            "Determining column types...\n",
            "Column types for Sample 1:\n",
            "First Name: string\n",
            "Last Name: string\n",
            "Mobile Number: numeric\n",
            "Date: string\n",
            "Email: string\n",
            "Address: string\n",
            "Column types for Sample 2:\n",
            "Email: string\n",
            "Account Balance: string\n",
            "User ID: string\n",
            "Meter No: string\n",
            "Meter Reading: numeric\n",
            "Comparing columns...\n",
            "Similar columns:\n",
            "Email (Sample 1) and Email (Sample 2) - Similarity: 1.00\n"
          ]
        }
      ],
      "source": [
        "import dask.dataframe as dd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.stats import pearsonr\n",
        "from typing import List, Tuple\n",
        "import multiprocessing as mp\n",
        "from functools import partial\n",
        "\n",
        "def determine_column_types(chunk: pd.DataFrame) -> dict:\n",
        "    column_types = {}\n",
        "    for column in chunk.columns:\n",
        "        if pd.api.types.is_string_dtype(chunk[column]):\n",
        "            column_types[column] = 'string'\n",
        "        elif pd.api.types.is_numeric_dtype(chunk[column]):\n",
        "            column_types[column] = 'numeric'\n",
        "        else:\n",
        "            column_types[column] = 'unknown'\n",
        "    return column_types\n",
        "\n",
        "def compare_columns(col1: pd.Series, col2: pd.Series) -> float:\n",
        "    if pd.api.types.is_string_dtype(col1) and pd.api.types.is_string_dtype(col2):\n",
        "        vectorizer = HashingVectorizer(n_features=1000)\n",
        "        vec1 = vectorizer.fit_transform(col1.astype(str).fillna(''))\n",
        "        vec2 = vectorizer.transform(col2.astype(str).fillna(''))\n",
        "        # Convert to numpy arrays before cosine similarity\n",
        "        vec1 = np.asarray(vec1.mean(axis=0))\n",
        "        vec2 = np.asarray(vec2.mean(axis=0))\n",
        "        return cosine_similarity(vec1, vec2)[0][0]\n",
        "    elif pd.api.types.is_numeric_dtype(col1) and pd.api.types.is_numeric_dtype(col2):\n",
        "        return abs(pearsonr(col1.fillna(0), col2.fillna(0))[0])\n",
        "    else:\n",
        "        return 0.0\n",
        "\n",
        "def process_chunk(chunk1: pd.DataFrame, df2: pd.DataFrame) -> List[Tuple[str, str, float]]:\n",
        "    similar_columns = []\n",
        "    for col1 in chunk1.columns:\n",
        "        for col2 in df2.columns:\n",
        "            similarity = compare_columns(chunk1[col1], df2[col2])\n",
        "            if similarity > 0.8:\n",
        "                similar_columns.append((col1, col2, similarity))\n",
        "    return similar_columns\n",
        "\n",
        "def main():\n",
        "    file1 = 'sample1.csv'\n",
        "    file2 = 'sample2.csv'\n",
        "\n",
        "    print(\"Loading second file...\")\n",
        "    df2 = dd.read_csv(file2).compute()\n",
        "\n",
        "    print(\"Loading first file in chunks...\")\n",
        "    df1 = dd.read_csv(file1, blocksize=\"10MB\")\n",
        "\n",
        "    print(\"Determining column types...\")\n",
        "    types1 = determine_column_types(df1.head(1))\n",
        "    types2 = determine_column_types(df2)\n",
        "\n",
        "    print(\"Column types for Sample 1:\")\n",
        "    for col, type in types1.items():\n",
        "        print(f\"{col}: {type}\")\n",
        "\n",
        "    print(\"Column types for Sample 2:\")\n",
        "    for col, type in types2.items():\n",
        "        print(f\"{col}: {type}\")\n",
        "\n",
        "    print(\"Comparing columns...\")\n",
        "\n",
        "    pool = mp.Pool(mp.cpu_count())\n",
        "    similar_columns = []\n",
        "\n",
        "    for delayed_chunk in df1.to_delayed():\n",
        "        chunk = delayed_chunk.compute()\n",
        "        chunk_results = pool.apply_async(process_chunk, args=(chunk, df2))\n",
        "        similar_columns.extend(chunk_results.get())\n",
        "\n",
        "    pool.close()\n",
        "    pool.join()\n",
        "\n",
        "    similar_columns = sorted(set(similar_columns), key=lambda x: x[2], reverse=True)\n",
        "\n",
        "    print(\"Similar columns:\")\n",
        "    for col1, col2, similarity in similar_columns:\n",
        "        print(f\"{col1} (Sample 1) and {col2} (Sample 2) - Similarity: {similarity:.2f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cx3hr35qriYY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}